[34m[1mwandb[0m: [33mWARNING[0m The project_name method is deprecated and will be removed in a future release. Please use `run.project` instead.
Logger: DiT, Run ID: wgeq1k68
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[34mSample shape: torch.Size([8, 192, 192, 20])[0m
[34mMin/Max: 0.0, 0.9960784912109375[0m
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Loading model from: /home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth
['autoencoder_kl', 'lpipsWithDisc']
[32mloaded autoencoder_kl successfully the game is on[0m
[32mModel initialized![0m
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
Loading `train_dataloader` to estimate number of stepping batches.
/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

  | Name        | Type        | Params
--------------------------------------------
0 | lpips_fn    | LPIPS       | 2.5 M
1 | diffnet     | DiT         | 308 M
2 | autoencoder | Autoencoder | 83.6 M
3 | loss_fn     | MSELoss     | 0
--------------------------------------------
308 M     Trainable params
86.2 M    Non-trainable params
394 M     Total params
1,579.105 Total estimated model params size (MB)
Epoch 0:  59%|â–Œ| 3166/5338 [1:13:05<50:08,  1.39s/it, loss=0.283, v_num=1k68, train/loss_step=0.313, train/psnr_step=17.20, train/ssim_step=0.212, train/hss_step=-1.35e-5, train/lpips_step=0.391, train/[32mTraining complete![0m
/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 20 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:70: FutureWarning: Importing `peak_signal_noise_ratio` from `torchmetrics.functional` was deprecated and will be removed in 2.0. Import `peak_signal_noise_ratio` from `torchmetrics.image` instead.
  _future_warning(
/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:70: FutureWarning: Importing `spectral_angle_mapper` from `torchmetrics.functional` was deprecated and will be removed in 2.0. Import `spectral_angle_mapper` from `torchmetrics.image` instead.
  _future_warning(
/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:378: UserWarning: `ModelCheckpoint(monitor='val/loss')` could not find the monitored key in the returned metrics: ['train/loss', 'train/loss_step', 'train/psnr', 'train/psnr_step', 'train/ssim', 'train/ssim_step', 'train/hss', 'train/hss_step', 'train/lpips', 'train/lpips_step', 'train/psd', 'train/psd_step', 'train/csi_radius_1_thresh_0.5', 'train/csi_radius_1_thresh_0.5_step', 'train/csi_radius_1_thresh_0.75', 'train/csi_radius_1_thresh_0.75_step', 'train/csi_radius_4_thresh_0.5', 'train/csi_radius_4_thresh_0.5_step', 'train/csi_radius_4_thresh_0.75', 'train/csi_radius_4_thresh_0.75_step', 'train/csi_radius_16_thresh_0.5', 'train/csi_radius_16_thresh_0.5_step', 'train/csi_radius_16_thresh_0.75', 'train/csi_radius_16_thresh_0.75_step', 'epoch', 'step']. HINT: Did you call `log('val/loss', value)` in the `LightningModule`?
  warning_cache.warn(m)
Epoch 0, global step 1000: 'val/loss' was not in top 3
Epoch 0, global step 2000: 'val/loss' was not in top 3
Epoch 0, global step 3000: 'val/loss' was not in top 3
/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:726: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...
  rank_zero_warn("Detected KeyboardInterrupt, attempting graceful shutdown...")
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt
