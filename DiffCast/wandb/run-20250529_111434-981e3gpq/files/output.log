============================================================
                 Experiment Start
============================================================
Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

train data: 10000, valid data: 16887, test_data: 20
Pixel Scale: 255.0, Threshold: (16, 74, 133, 160, 181, 219)
Main Model Parameters: 48.87M
============ Running training ============
    Num examples = 10000
    Num Epochs = 1
    Instantaneous batch size per GPU = 1
    Total train batch size (w. parallel, distributed & accumulation) = 1
    Total optimization steps = 10000
optimizer: AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.95)
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0
    maximize: False
    weight_decay: 0.0
) with init lr: 0.0001
Data Loading Time: 0.09973859786987305
True
gpu_nums: 1, gpu_id: 0
Epoch 0/1, Step 5/10000:   0%|â–Ž                                                                                                                                                                                                                                                                                                                                                                                                                                   | 6/10000 [00:03<1:05:39,  2.54it/s, lr=6e-7, total_loss=0.34]Traceback (most recent call last):
frames_in shape: torch.Size([1, 10, 1, 384, 384])
backbone_output shape: torch.Size([1, 10, 1, 384, 384])
residual shape: torch.Size([1, 10, 1, 384, 384])
frames_gt shape: torch.Size([1, 10, 1, 384, 384])
frames_in shape: torch.Size([1, 10, 1, 384, 384])
backbone_output shape: torch.Size([1, 10, 1, 384, 384])
residual shape: torch.Size([1, 10, 1, 384, 384])
frames_gt shape: torch.Size([1, 10, 1, 384, 384])
frames_in shape: torch.Size([1, 10, 1, 384, 384])
backbone_output shape: torch.Size([1, 10, 1, 384, 384])
residual shape: torch.Size([1, 10, 1, 384, 384])
frames_gt shape: torch.Size([1, 10, 1, 384, 384])
frames_in shape: torch.Size([1, 10, 1, 384, 384])
backbone_output shape: torch.Size([1, 10, 1, 384, 384])
residual shape: torch.Size([1, 10, 1, 384, 384])
frames_gt shape: torch.Size([1, 10, 1, 384, 384])
frames_in shape: torch.Size([1, 10, 1, 384, 384])
backbone_output shape: torch.Size([1, 10, 1, 384, 384])
residual shape: torch.Size([1, 10, 1, 384, 384])
frames_gt shape: torch.Size([1, 10, 1, 384, 384])
frames_in shape: torch.Size([1, 10, 1, 384, 384])
backbone_output shape: torch.Size([1, 10, 1, 384, 384])
residual shape: torch.Size([1, 10, 1, 384, 384])
frames_gt shape: torch.Size([1, 10, 1, 384, 384])
frames_in shape: torch.Size([1, 10, 1, 384, 384])
backbone_output shape: torch.Size([1, 10, 1, 384, 384])
residual shape: torch.Size([1, 10, 1, 384, 384])
frames_gt shape: torch.Size([1, 10, 1, 384, 384])
  File "/home/vatsal/NWM/DiffCast/run.py", line 567, in <module>
    main()
  File "/home/vatsal/NWM/DiffCast/run.py", line 556, in main
    exp.train()
  File "/home/vatsal/NWM/DiffCast/run.py", line 409, in train
    loss_dict = self._train_batch(batch)
  File "/home/vatsal/NWM/DiffCast/run.py", line 477, in _train_batch
    _, loss = self.model.predict(frames_in=frames_in, frames_gt=frames_out, compute_loss=True)
  File "/home/vatsal/NWM/DiffCast/models/diffcast.py", line 952, in predict
    loss = self._predict(frames_in, frames_gt)
  File "/home/vatsal/NWM/DiffCast/models/diffcast.py", line 998, in _predict
    if torch.isnan(loss):
KeyboardInterrupt
