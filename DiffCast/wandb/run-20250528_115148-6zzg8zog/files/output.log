============================================================
                 Experiment Start
============================================================
Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: bf16

train data: 71436, valid data: 16887, test_data: 4332
Pixel Scale: 255.0, Threshold: (16, 74, 133, 160, 181, 219)
Main Model Parameters: 58.45M
============ Running training ============
    Num examples = 71436
    Num Epochs = 2
    Instantaneous batch size per GPU = 1
    Total train batch size (w. parallel, distributed & accumulation) = 1
    Total optimization steps = 142872
optimizer: AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.95)
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0
    maximize: False
    weight_decay: 0.0
) with init lr: 0.0001
Data Loading Time: 0.10435628890991211
True
gpu_nums: 1, gpu_id: 0
  0%|                                                             | 0/142872 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/vatsal/NWM/DiffCast/run.py", line 577, in <module>
    main()
  File "/home/vatsal/NWM/DiffCast/run.py", line 566, in main
    exp.train()
  File "/home/vatsal/NWM/DiffCast/run.py", line 421, in train
    loss_dict = self._train_batch(batch)
  File "/home/vatsal/NWM/DiffCast/run.py", line 491, in _train_batch
    raise ValueError("Loss is None, please check the model predict function")
ValueError: Loss is None, please check the model predict function
