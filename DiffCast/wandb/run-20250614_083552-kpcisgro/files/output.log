============================================================
                 Experiment Start
============================================================
Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

Loading data
train data: 9921, valid data: 2345, test_data: 601
Pixel Scale: 255.0, Threshold: (16, 74, 133, 160, 181, 219)
Batch Shape: torch.Size([6, 25, 1, 128, 128]), Type: torch.float32
Batch Shape: torch.Size([12, 25, 1, 128, 128]), Type: torch.float32
Batch Shape: torch.Size([12, 25, 1, 128, 128]), Type: torch.float32
Building model
Main Model Parameters: 2.42M
============ Running training ============
    Num examples = 9921
    Num Epochs = 21
    Instantaneous batch size per GPU = 6
    Total train batch size (w. parallel, distributed & accumulation) = 6
    Total optimization steps = 208341
optimizer: AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.95)
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 1e-05
    lr: 0.0
    maximize: False
    weight_decay: 0.0
) with init lr: 1e-05
Data Loading Time: 0.3912661075592041
True
gpu_nums: 1, gpu_id: 0
Training Now
Epoch 0/21, Step 1597/9921:   1%|          | 1598/208341 [03:44<6:53:20,  8.34it/s, lr=1e-5, total_loss=0.00433]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7df44e27b280>
Traceback (most recent call last):
  File "/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1663, in __del__
    self._shutdown_workers()
  File "/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1627, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/multiprocessing/popen_fork.py", line 40, in wait
    if not wait([self.sentinel], timeout):
  File "/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt:
Traceback (most recent call last):
  File "/home/vatsal/NWM/weather/DiffCast/run.py", line 591, in <module>
    main()
  File "/home/vatsal/NWM/weather/DiffCast/run.py", line 580, in main
    exp.train()
  File "/home/vatsal/NWM/weather/DiffCast/run.py", line 423, in train
    self.accelerator.backward(loss_dict['total_loss'])
  File "/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/accelerate/accelerator.py", line 2001, in backward
    loss.backward(**kwargs)
  File "/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/vatsal/NWM/weather/DiffCast/run.py", line 591, in <module>
    main()
  File "/home/vatsal/NWM/weather/DiffCast/run.py", line 580, in main
    exp.train()
  File "/home/vatsal/NWM/weather/DiffCast/run.py", line 423, in train
    self.accelerator.backward(loss_dict['total_loss'])
  File "/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/accelerate/accelerator.py", line 2001, in backward
    loss.backward(**kwargs)
  File "/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
