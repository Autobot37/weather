============================================================
                 Experiment Start
============================================================
Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: bf16

train data: 71436, valid data: 16887, test_data: 100
Pixel Scale: 255.0, Threshold: (16, 74, 133, 160, 181, 219)
Main Model Parameters: 48.87M
============ Running training ============
    Num examples = 71436
    Num Epochs = 2
    Instantaneous batch size per GPU = 1
    Total train batch size (w. parallel, distributed & accumulation) = 1
    Total optimization steps = 142872
optimizer: AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.95)
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0
    maximize: False
    weight_decay: 0.0
) with init lr: 0.0001
Data Loading Time: 0.12756109237670898
True
gpu_nums: 1, gpu_id: 0
Epoch 0/2, Step 111/71436:   0%|                                                                                          | 112/142872 [00:38<12:47:01,  3.10it/s, lr=1.12e-5, total_loss=1.2]Traceback (most recent call last):
backbone_net.torch_nn_module.decoder.cross_blocks.0.0.ffn_l.0.ffn_1.weight
backbone_net.torch_nn_module.decoder.cross_blocks.0.0.ffn_l.0.ffn_1.bias
backbone_net.torch_nn_module.decoder.cross_blocks.0.0.ffn_l.0.ffn_2.weight
backbone_net.torch_nn_module.decoder.cross_blocks.0.0.ffn_l.0.ffn_2.bias
  File "/home/vatsal/NWM/DiffCast/run.py", line 577, in <module>
    main()
  File "/home/vatsal/NWM/DiffCast/run.py", line 566, in main
    exp.train()
  File "/home/vatsal/NWM/DiffCast/run.py", line 421, in train
    self.accelerator.backward(loss_dict['total_loss'])
  File "/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/accelerate/accelerator.py", line 2001, in backward
    loss.backward(**kwargs)
  File "/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/home/vatsal/miniconda3/envs/earthformer/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt
