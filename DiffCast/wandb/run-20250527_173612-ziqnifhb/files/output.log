============================================================
                 Experiment Start
============================================================
Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: bf16

train data: 71436, valid data: 16887, test_data: 4332
Pixel Scale: 255.0, Threshold: (16, 74, 133, 160, 181, 219)
layer  0 input dim  64  hidden dim  128
layer  1 input dim  128  hidden dim  128
layer  2 input dim  128  hidden dim  64
Main Model Parameters: 49.41M
============ Running training ============
    Num examples = 71436
    Num Epochs = 2
    Instantaneous batch size per GPU = 1
    Total train batch size (w. parallel, distributed & accumulation) = 1
    Total optimization steps = 142872
optimizer: AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.95)
    capturable: False
    decoupled_weight_decay: True
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0001
    lr: 0.0
    maximize: False
    weight_decay: 0.0
) with init lr: 0.0001
Data Loading Time: 0.11780810356140137
True
gpu_nums: 1, gpu_id: 0
sampling frags:: 100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.49s/it]
Traceback (most recent call last):██████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.49s/it]
  File "/home/vatsal/NWM/DiffCast/run.py", line 577, in <module>
    main()
  File "/home/vatsal/NWM/DiffCast/run.py", line 566, in main
    exp.train()
  File "/home/vatsal/NWM/DiffCast/run.py", line 421, in train
    loss_dict = self._train_batch(batch)
  File "/home/vatsal/NWM/DiffCast/run.py", line 489, in _train_batch
    _, loss = self.model.predict(frames_in=frames_in, frames_gt=frames_out, compute_loss=True)
  File "/home/vatsal/NWM/DiffCast/models/diffcast.py", line 953, in predict
    raise NotImplementedError("We are sorry that we do not support training process for now because of business limitation ")
NotImplementedError: We are sorry that we do not support training process for now because of business limitation
