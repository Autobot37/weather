{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "976c9ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDIMScheduler\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from omegaconf import OmegaConf\n",
    "from CasCast.networks.prediff.taming.autoencoder_kl import AutoencoderKL\n",
    "from pipeline.modeldefinitions.dit import CasFormer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, EarlyStopping\n",
    "from pipeline.utils import load_checkpoint_cascast\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\"\"\"\n",
    "B T C H W   \n",
    "\"\"\"\n",
    "class DiT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.model = CasFormer(arch='DiT-custom', config=config.Model)\n",
    "        self.scheduler = DDIMScheduler(num_train_timesteps=config.timesteps)\n",
    "\n",
    "    def forward(self, noisy: torch.Tensor, timesteps: torch.Tensor, cond: torch.Tensor):\n",
    "        return self.model(noisy, timesteps, cond)\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.autoencoder = AutoencoderKL(**config)\n",
    "        self.autoencoder.eval() \n",
    "        load_checkpoint_cascast(\"/home/vatsal/NWM/weather/pipeline/autoencoder_ckpt.pth\", self.autoencoder)\n",
    "        for param in self.autoencoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.autoencoder.requires_grad_(False)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def encode(self, x):\n",
    "        # x: (B, T, C, H, W) [0, 1]\n",
    "        B, T, _, H, W = x.shape\n",
    "        out = []\n",
    "        for i in range(T):\n",
    "            frame = x[:, i]  # [B, C, H, W]\n",
    "            z = self.autoencoder.encode(frame).sample()\n",
    "            out.append(z.unsqueeze(1))\n",
    "        return torch.cat(out, dim=1)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def decode(self, x):\n",
    "        # x: (B, T, latent_C, H, W) [0, 1]\n",
    "        B, T, C, H, W = x.shape\n",
    "        out = []\n",
    "        for i in range(T):\n",
    "            frame = x[:, i]\n",
    "            dec = self.autoencoder.decode(frame)\n",
    "            out.append(dec.unsqueeze(1))\n",
    "        return torch.cat(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bc28138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['autoencoder_kl', 'lpipsWithDisc']\n",
      "\u001b[32mloaded autoencoder_kl successfully the game is on\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "config = OmegaConf.load(\"/home/vatsal/NWM/weather/pipeline/configs/models/vae.yaml\")\n",
    "autoencoder = Autoencoder(config).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f85c68c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384, 384, 49)\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/vatsal/Dataserver/NWM/datasets/sevir/data/vil/2017\"\n",
    "import os\n",
    "files = os.listdir(path)\n",
    "file = files[0]\n",
    "import h5py\n",
    "data = h5py.File(os.path.join(path, file), 'r')\n",
    "vil = data['vil'][10]\n",
    "print(vil.shape)  # (T, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75a27e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(vil).unsqueeze(0)  # (1, H, W, T)\n",
    "x = x.permute(0, 3, 1, 2).unsqueeze(2)  # (1, T, C, H, W)\n",
    "x = x.float() / 255.0  # Normalize to [0, 1]\n",
    "enc = autoencoder.encode(x.to(\"cuda\"))  # (1, T, latent_C, H', W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45b76b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min enc: -8.521828651428223\n",
      "max enc: 20.1545352935791\n"
     ]
    }
   ],
   "source": [
    "print(\"min enc:\", enc.min().item())\n",
    "print(\"max enc:\", enc.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9795a473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Original tensor\n",
    "x = torch.randn((4, 64, 64))\n",
    "tmp_x = x.clone()\n",
    "\n",
    "# 1) Save reference slice\n",
    "x0 = x[0:1]              # shape (1, 64, 64)\n",
    "\n",
    "# 2) Subtract x0\n",
    "x = x - x0               # now centered around zero\n",
    "\n",
    "\n",
    "# 3) Normalize to [0, 1]\n",
    "x = (x + 1) / 2\n",
    "\n",
    "# send\n",
    "\n",
    "# 4) Rescale back to [-1, 1]\n",
    "x = x * 2 - 1\n",
    "\n",
    "# 5) Add x0 back\n",
    "x = x + x0\n",
    "\n",
    "# Check\n",
    "print(torch.isclose(tmp_x, x, atol=1e-5).all())  # Should print: True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bae38c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earthformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
