Train dataset size: 230
Test dataset size: 247
Validation dataset size: 61
Sample shape: torch.Size([16, 384, 384, 20]), dtype: torch.float32. maximum value: 0.9960784912109375, minimum value: 0.0
Sample shape: torch.Size([16, 384, 384, 20]), dtype: torch.float32. maximum value: 0.9960784912109375, minimum value: 0.0
Sample shape: torch.Size([16, 384, 384, 20]), dtype: torch.float32. maximum value: 0.9960784912109375, minimum value: 0.0
Epoch 1/3 [Train]:   0%|                                                        | 0/230 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/home/vatsal/NWM/fno_sevir/fno_sevir2.py", line 102, in <module>
    predicted_frames = model(input_frames)
  File "/home/vatsal/NWM/SSBware/senv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/vatsal/NWM/SSBware/senv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/vatsal/NWM/SSBware/senv/lib/python3.13/site-packages/neuralop/models/fno.py", line 378, in forward
    x = self.fno_blocks(x, layer_idx, output_shape=output_shape[layer_idx])
  File "/home/vatsal/NWM/SSBware/senv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/vatsal/NWM/SSBware/senv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/vatsal/NWM/SSBware/senv/lib/python3.13/site-packages/neuralop/layers/fno_block.py", line 277, in forward
    return self.forward_with_postactivation(x, index, output_shape)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vatsal/NWM/SSBware/senv/lib/python3.13/site-packages/neuralop/layers/fno_block.py", line 292, in forward_with_postactivation
    x_fno = self.convs[index](x, output_shape=output_shape)
  File "/home/vatsal/NWM/SSBware/senv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/vatsal/NWM/SSBware/senv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/vatsal/NWM/SSBware/senv/lib/python3.13/site-packages/neuralop/layers/spectral_convolution.py", line 468, in forward
    out_fft[slices_x] = self._contract(x[slices_x], weight, separable=self.separable)
                        ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vatsal/NWM/SSBware/senv/lib/python3.13/site-packages/neuralop/layers/spectral_convolution.py", line 46, in _contract_dense
    return tl.einsum(eq, x, weight)
           ~~~~~~~~~^^^^^^^^^^^^^^^
  File "/home/vatsal/NWM/SSBware/senv/lib/python3.13/site-packages/tensorly/backend/__init__.py", line 202, in wrapped_backend_method
    return getattr(
           ~~~~~~~~
        cls._THREAD_LOCAL_DATA.__dict__.get("backend", cls._backend), name
        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    )(*args, **kwargs)
    ~^^^^^^^^^^^^^^^^^
  File "/home/vatsal/NWM/SSBware/senv/lib/python3.13/site-packages/tensorly/plugins.py", line 77, in cached_einsum
    return expression(*args)
  File "/home/vatsal/NWM/SSBware/senv/lib/python3.13/site-packages/opt_einsum/contract.py", line 895, in __call__
    return self._contract(ops, out=out, backend=backend, evaluate_constants=evaluate_constants)
           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vatsal/NWM/SSBware/senv/lib/python3.13/site-packages/opt_einsum/contract.py", line 816, in _contract
    return _core_contract(
        list(arrays),
    ...<4 lines>...
        **self.kwargs,
    )
  File "/home/vatsal/NWM/SSBware/senv/lib/python3.13/site-packages/opt_einsum/contract.py", line 702, in _core_contract
    new_view = _einsum(einsum_str, *tmp_operands, backend=backend, out=out_kwarg, **kwargs)
  File "/home/vatsal/NWM/SSBware/senv/lib/python3.13/site-packages/opt_einsum/sharing.py", line 164, in cached_einsum
    return einsum(*args, **kwargs)
  File "/home/vatsal/NWM/SSBware/senv/lib/python3.13/site-packages/opt_einsum/contract.py", line 451, in _einsum
    return fn(einsum_str, *operands, **kwargs)
  File "/home/vatsal/NWM/SSBware/senv/lib/python3.13/site-packages/opt_einsum/backends/torch.py", line 48, in einsum
    return torch.einsum(equation, operands)
           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/home/vatsal/NWM/SSBware/senv/lib/python3.13/site-packages/torch/functional.py", line 417, in einsum
    return einsum(equation, *_operands)
  File "/home/vatsal/NWM/SSBware/senv/lib/python3.13/site-packages/torch/functional.py", line 422, in einsum
    return _VF.einsum(equation, operands)  # type: ignore[attr-defined]
           ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 264.00 MiB. GPU 0 has a total capacity of 23.64 GiB of which 255.06 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 59.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
